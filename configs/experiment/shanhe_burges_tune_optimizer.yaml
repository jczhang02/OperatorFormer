# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: burges
  - override /model: operatorformer
  - override /callbacks: default
  - override /trainer: gpu
  - override /logger: tensorboard

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["RMSprop"]

seed: 114514

trainer:
  min_epochs: 20000
  max_epochs: 20000
  check_val_every_n_epoch: 1
  gradient_clip_val: 0.5
  detect_anomaly: True
  deterministic: True

model:
  optimizer:
    _target_: torch.optim.Adam
    lr: 8.0e-4
  scheduler:
    _target_: torch.optim.lr_scheduler.OneCycleLR
    _partial_: true
    max_lr: ${model.optimizer.lr}
    total_steps: ${trainer.max_epochs}
    # total_steps: 10
    div_factor: 1
    pct_start: 0.3
    final_div_factor: 1
  compile: false
  net:
    input_encoder_config:
      attn_type: "galerkin"
      nhead: 1
      num_layers: 4
      scale: [8, 4, 4, 2]

data:
  batch_size: 16
  train_val_test_split: [1_024, 100, 200]
logger:
  tensorboard:
    name: "Burges 1D RMSprop"
